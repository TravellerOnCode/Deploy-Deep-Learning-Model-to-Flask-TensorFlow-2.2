# -*- coding: utf-8 -*-
"""The FLASK Server

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1UjV2rff6rJzRAwJJuUkohnOUhLkQFuFR
"""

import string
import tensorflow as tf
from tensorflow.keras.preprocessing import sequence
from flask import Flask, jsonify, request
import pickle
import nltk
from nltk.tokenize import word_tokenize

nltk.download('punkt')

with open('./files/<YOUR TOKENIZER FILE>','rb') as f:
  tokenizer = pickle.load(f)


#functions to pre-process data
def clean_data(text):

    # split into words
    tokens = word_tokenize(text)
    # convert to lower case
    tokens = [w.lower() for w in tokens]
    # remove punctuation from each word
    table = str.maketrans('', '', string.punctuation)
    stripped = [w.translate(table) for w in tokens]
    # remove remaining tokens that are not alphabetic
    words = [word for word in stripped if word.isalpha()]
    
    str1 = ""
    for i in words:
      str1 = str1 + i + " "
    return str1


def transform(data):
  essays = []
  for d in data:
    essays.append(d.split())
  return essays

def prepare_data(single_data_):
  data_ = []
  MAX_SEQUENCE_LENGTH = 500 #-- working well
  trunc_type='post'
  padding_type='post'
  text = clean_data(single_data_)
  data_.append(text)
  #print(data_)
  preproc_data = tokenizer.texts_to_sequences(data_)
  preproc_data = sequence.pad_sequences(preproc_data, maxlen=MAX_SEQUENCE_LENGTH,padding=padding_type, truncating=trunc_type)

  return preproc_data #,misspelled


"""#The Flask Server"""

print('Starting Server')
model = tf.keras.models.load_model('./files/<YOUR SAVED MODEL>')
    
# app
app = Flask(__name__)

# routes
@app.route("/",methods=['GET','POST'])
def predict():
    
    data = request.get_json(force=True)
    pass_value = data['password']
    data_vec = prepare_data(data['text'])
    
    print('Received Data :',data)
    if pass_value != 'AQUA121G890UP002':
        message = 'Unauthorized request'
        return message
    
    data_vec_ = data_vec
    results = model.predict(data_vec_)[0]
    print (results)
    score = results[0]*10
    score = round(score,2)
    # send back to browser
    output = {'results': float(score)}
    return jsonify(results=output)

if __name__ == '__main__':
    app.run(port = 5000)
